{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Enunciado</th>\n",
       "      <th>Tópico</th>\n",
       "      <th>Contexto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>Meu primeiro programa\\nEscreva um programa que...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>996</td>\n",
       "      <td>Impressão de caracteres na tela\\nEscreva um pr...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>Impressão de caracteres na tela (Bart Simpson)...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>Operadores aritméticos\\nQual o valor de X para...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>578</td>\n",
       "      <td>Operadores aritméticos \\nQual o valor de Y par...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                          Enunciado       Tópico  \\\n",
       "0   994  Meu primeiro programa\\nEscreva um programa que...  Ambientação   \n",
       "1   996  Impressão de caracteres na tela\\nEscreva um pr...  Ambientação   \n",
       "2   999  Impressão de caracteres na tela (Bart Simpson)...  Ambientação   \n",
       "3  1000  Operadores aritméticos\\nQual o valor de X para...  Ambientação   \n",
       "4   578  Operadores aritméticos \\nQual o valor de Y par...  Ambientação   \n",
       "\n",
       "     Contexto  \n",
       "0      Outros  \n",
       "1      Outros  \n",
       "2      Outros  \n",
       "3  Matemático  \n",
       "4  Matemático  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "df = pd.read_csv('../dados_categorizados_completo_novo.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matemático         261\n",
       "Comercial          120\n",
       "Jogos               96\n",
       "Escolar             79\n",
       "Outros              59\n",
       "Trânsito            43\n",
       "Esporte             42\n",
       "Física              36\n",
       "Bancário            35\n",
       "RH                  35\n",
       "Filmes e séries     30\n",
       "População           25\n",
       "Química             23\n",
       "Pessoa              22\n",
       "Data e hora         21\n",
       "Segurança           20\n",
       "Pesquisa            18\n",
       "Meio ambiente       18\n",
       "Saúde               17\n",
       "Consumo             16\n",
       "Geografia           11\n",
       "Produção             7\n",
       "Computacional        6\n",
       "Imposto              5\n",
       "Name: Contexto, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Contexto.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X = df['Enunciado']\n",
    "y = df['Contexto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __call__(self, text):\n",
    "        doc=nlp(text)\n",
    "        tokens=[]\n",
    "        for token in doc:\n",
    "            if(token.text.isalpha() and len(token.text)>=2):\n",
    "                tokens+=[token]\n",
    "        return [t.lemma_ for t in tokens if t not in nlp.Defaults.stop_words]\n",
    "pipeline= LinearSVC(\n",
    "    penalty='l2',\n",
    "    loss='squared_hinge',\n",
    "    dual=True,\n",
    "    tol=0.001,\n",
    "    C=10.0,\n",
    "    multi_class='ovr',\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=10,\n",
    "    class_weight=None,\n",
    "    verbose=0,\n",
    "    random_state=None,\n",
    "    max_iter=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['acercar', 'algum', 'antar', 'apoiar', 'baixar', 'caminhar', 'ceder', 'cincar', 'comer', 'conhecer', 'custar', 'dever', 'devir', 'direito', 'entrar', 'estevar', 'estivar', 'falto', 'formar', 'grupar', 'irar', 'ligar', 'mear', 'nado', 'nenhum', 'nó', 'o', 'obrigar', 'oitavar', 'orar', 'outro', 'parecer', 'parir', 'pelar', 'pontar', 'pôr', 'quantum', 'quartar', 'querer', 'quietar', 'quintar', 'segundar', 'seriar', 'sobrar', 'suar', 'tardar', 'terceirar', 'umar', 'vezar', 'vir', 'vário'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words={'acerca', 'ademais', 'adeus',\n",
       "                                             'agora', 'ainda', 'algo',\n",
       "                                             'alguma...\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7fe5681b99d0>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('svd',\n",
       "                 TruncatedSVD(algorithm='randomized', n_components=300,\n",
       "                              n_iter=5, random_state=None, tol=0.0)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=10.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=10,\n",
       "                           loss='squared_hinge', max_iter=10000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_lsvc2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=nlp.Defaults.stop_words,\n",
    "                            tokenizer=LemmaTokenizer(),sublinear_tf=True)),\n",
    "                            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)),\n",
    "                            ('clf',pipeline),\n",
    "    ])\n",
    "text_clf_lsvc2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_sentences(da,maximum,synonyms_lexicon):\n",
    "    strings=[]\n",
    "    for elemento in da['Enunciado']:\n",
    "        if(len(da)+len(strings)<maximum):\n",
    "            contador=0\n",
    "            lista=elemento.split()\n",
    "            while(contador<len(lista)):\n",
    "                if(lista[contador] in synonyms_lexicon):\n",
    "                    lista[contador]=synonyms_lexicon[lista[contador]][0]\n",
    "                contador+=1\n",
    "            strings+=[' '.join(lista)]\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    new_sentences = pd.Series(strings)\n",
    "    return new_sentences\n",
    "\n",
    "def get_synonyms_lexicon(path):\n",
    "    synonyms_lexicon = {}\n",
    "    text_entries = [l.strip() for l in open(path).readlines()]\n",
    "    for e in text_entries:\n",
    "        e = e.split(' ')\n",
    "        k = e[0]\n",
    "        v = e[1:len(e)]\n",
    "        synonyms_lexicon[k] = v\n",
    "    return synonyms_lexicon\n",
    "\n",
    "synonyms_lexicon = get_synonyms_lexicon('../paráfrase/arq3.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:169: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:170: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:171: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:172: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:173: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:174: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:175: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:176: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:177: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:178: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:179: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:180: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:181: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:182: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:183: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:184: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:185: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:186: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:187: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:188: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:189: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:190: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:191: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:198: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "maximum = df.Contexto.value_counts().max()\n",
    "g = df.groupby('Contexto')\n",
    "\n",
    "\n",
    "mat = g.get_group('Matemático')\n",
    "comercial = g.get_group('Comercial')\n",
    "jogos = g.get_group('Jogos')\n",
    "escolar = g.get_group('Escolar')\n",
    "outros = g.get_group('Outros')\n",
    "transito = g.get_group('Trânsito')\n",
    "esporte = g.get_group('Esporte')\n",
    "fisica = g.get_group('Física')\n",
    "bancario = g.get_group('Bancário')\n",
    "RH = g.get_group('RH')\n",
    "f_s = g.get_group('Filmes e séries')\n",
    "populacao = g.get_group('População')\n",
    "quimica = g.get_group('Química')\n",
    "pessoa = g.get_group('Pessoa')\n",
    "d_h = g.get_group('Data e hora')\n",
    "seguranca = g.get_group('Segurança')\n",
    "ambiente = g.get_group('Meio ambiente')\n",
    "pesquisa = g.get_group('Pesquisa')\n",
    "saude = g.get_group('Saúde')\n",
    "consumo = g.get_group('Consumo')\n",
    "geografia = g.get_group('Geografia')\n",
    "producao = g.get_group('Produção')\n",
    "imposto = g.get_group('Imposto')\n",
    "computacional = g.get_group('Computacional')\n",
    "\n",
    "new_jogos = get_new_sentences(jogos,maximum,synonyms_lexicon)\n",
    "new_comercial = get_new_sentences(comercial,maximum,synonyms_lexicon)\n",
    "new_escolar = get_new_sentences(escolar,maximum,synonyms_lexicon)\n",
    "new_outros = get_new_sentences(outros,maximum,synonyms_lexicon)\n",
    "new_transito = get_new_sentences(transito,maximum,synonyms_lexicon)\n",
    "new_esporte = get_new_sentences(esporte,maximum,synonyms_lexicon)\n",
    "new_fisica = get_new_sentences(fisica,maximum,synonyms_lexicon)\n",
    "new_bancario = get_new_sentences(bancario,maximum,synonyms_lexicon)\n",
    "new_RH = get_new_sentences(RH,maximum,synonyms_lexicon)\n",
    "new_f_s = get_new_sentences(f_s,maximum,synonyms_lexicon)\n",
    "new_populacao = get_new_sentences(populacao,maximum,synonyms_lexicon)\n",
    "new_quimica = get_new_sentences(quimica,maximum,synonyms_lexicon)\n",
    "new_pessoa = get_new_sentences(pessoa,maximum,synonyms_lexicon)\n",
    "new_d_h = get_new_sentences(d_h,maximum,synonyms_lexicon)\n",
    "new_seguranca = get_new_sentences(seguranca,maximum,synonyms_lexicon)\n",
    "new_pesquisa = get_new_sentences(pesquisa,maximum,synonyms_lexicon)\n",
    "new_ambiente = get_new_sentences(ambiente,maximum,synonyms_lexicon)\n",
    "new_saude = get_new_sentences(saude,maximum,synonyms_lexicon)\n",
    "new_consumo = get_new_sentences(consumo,maximum,synonyms_lexicon)\n",
    "new_geografia = get_new_sentences(geografia,maximum,synonyms_lexicon)\n",
    "new_producao = get_new_sentences(producao,maximum,synonyms_lexicon)\n",
    "new_computacional = get_new_sentences(computacional,maximum,synonyms_lexicon)\n",
    "new_imposto = get_new_sentences(imposto,maximum,synonyms_lexicon)\n",
    "\n",
    "\n",
    "new_jogos = pd.DataFrame(new_jogos,columns=['Enunciado'])\n",
    "new_jogos['Contexto'] = 'Jogos'\n",
    "new_jogos['Tópico']='Nada'\n",
    "\n",
    "new_comercial = pd.DataFrame(new_comercial,columns=['Enunciado'])\n",
    "new_comercial['Contexto'] = 'Comercial'\n",
    "new_comercial['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_escolar = pd.DataFrame(new_escolar,columns=['Enunciado'])\n",
    "new_escolar['Contexto'] = 'Escolar'\n",
    "new_escolar['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_outros = pd.DataFrame(new_outros,columns=['Enunciado'])\n",
    "new_outros['Contexto'] = 'Outros'\n",
    "new_outros['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_transito = pd.DataFrame(new_transito,columns=['Enunciado'])\n",
    "new_transito['Contexto'] = 'Trânsito'\n",
    "new_transito['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_esporte = pd.DataFrame(new_esporte,columns=['Enunciado'])\n",
    "new_esporte['Contexto'] = 'Esporte'\n",
    "new_esporte['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_fisica = pd.DataFrame(new_fisica,columns=['Enunciado'])\n",
    "new_fisica['Contexto'] = 'Física'\n",
    "new_fisica['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_bancario = pd.DataFrame(new_bancario,columns=['Enunciado'])\n",
    "new_bancario['Contexto'] = 'Bancário'\n",
    "new_bancario['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_RH = pd.DataFrame(new_RH,columns=['Enunciado'])\n",
    "new_RH['Contexto'] = 'RH'\n",
    "new_RH['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_f_s = pd.DataFrame(new_f_s,columns=['Enunciado'])\n",
    "new_f_s['Contexto'] = 'Filmes e séries'\n",
    "new_f_s['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_populacao = pd.DataFrame(new_populacao,columns=['Enunciado'])\n",
    "new_populacao['Contexto'] = 'População'\n",
    "new_populacao['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_quimica = pd.DataFrame(new_quimica,columns=['Enunciado'])\n",
    "new_quimica['Contexto'] = 'Química'\n",
    "new_quimica['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_pessoa = pd.DataFrame(new_pessoa,columns=['Enunciado'])\n",
    "new_pessoa['Contexto'] = 'Pessoa'\n",
    "new_pessoa['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_d_h = pd.DataFrame(new_d_h,columns=['Enunciado'])\n",
    "new_d_h['Contexto'] = 'Data e hora'\n",
    "new_d_h['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_seguranca = pd.DataFrame(new_seguranca,columns=['Enunciado'])\n",
    "new_seguranca['Contexto'] = 'Segurança'\n",
    "new_seguranca['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_pesquisa = pd.DataFrame(new_pesquisa,columns=['Enunciado'])\n",
    "new_pesquisa['Contexto'] = 'Pesquisa'\n",
    "new_pesquisa['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_ambiente = pd.DataFrame(new_ambiente,columns=['Enunciado'])\n",
    "new_ambiente['Contexto'] = 'Meio ambiente'\n",
    "new_ambiente['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_saude = pd.DataFrame(new_saude,columns=['Enunciado'])\n",
    "new_saude['Contexto'] = 'Saúde'\n",
    "new_saude['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_consumo = pd.DataFrame(new_consumo,columns=['Enunciado'])\n",
    "new_consumo['Contexto'] = 'Consumo'\n",
    "new_consumo['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_geografia = pd.DataFrame(new_geografia,columns=['Enunciado'])\n",
    "new_geografia['Contexto'] = 'Geografia'\n",
    "new_geografia['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_producao = pd.DataFrame(new_producao,columns=['Enunciado'])\n",
    "new_producao['Contexto'] = 'Produção'\n",
    "new_producao['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_computacional= pd.DataFrame(new_computacional,columns=['Enunciado'])\n",
    "new_computacional['Contexto'] = 'Computacional'\n",
    "new_computacional['Tópico']='Nada'\n",
    "\n",
    "\n",
    "new_imposto= pd.DataFrame(new_imposto,columns=['Enunciado'])\n",
    "new_imposto['Contexto'] = 'Imposto'\n",
    "new_imposto['Tópico']='Nada'\n",
    "\n",
    "\n",
    "jogos_extended = pd.concat([jogos, new_jogos], keys = ['Enunciado', 'Contexto'])\n",
    "comercial_extended = pd.concat([comercial, new_comercial], keys = ['Enunciado', 'Contexto'])\n",
    "escolar_extended = pd.concat([escolar, new_escolar], keys = ['Enunciado', 'Contexto'])\n",
    "outros_extended = pd.concat([outros, new_outros], keys = ['Enunciado', 'Contexto'])\n",
    "transito_extended = pd.concat([transito, new_transito], keys = ['Enunciado', 'Contexto'])\n",
    "esporte_extended = pd.concat([esporte, new_esporte], keys = ['Enunciado', 'Contexto'])\n",
    "fisica_extended = pd.concat([fisica, new_fisica], keys = ['Enunciado', 'Contexto'])\n",
    "bancario_extended = pd.concat([bancario, new_bancario], keys = ['Enunciado', 'Contexto'])\n",
    "RH_extended = pd.concat([RH, new_RH], keys = ['Enunciado', 'Contexto'])\n",
    "f_s_extended = pd.concat([f_s, new_f_s], keys = ['Enunciado', 'Contexto'])\n",
    "populacao_extended = pd.concat([populacao, new_populacao], keys = ['Enunciado', 'Contexto'])\n",
    "quimica_extended = pd.concat([quimica, new_quimica], keys = ['Enunciado', 'Contexto'])\n",
    "pessoa_extended = pd.concat([pessoa, new_pessoa], keys = ['Enunciado', 'Contexto'])\n",
    "d_h_extended = pd.concat([d_h, new_d_h], keys = ['Enunciado', 'Contexto'])\n",
    "seguranca_extended = pd.concat([seguranca, new_seguranca], keys = ['Enunciado', 'Contexto'])\n",
    "pesquisa_extended = pd.concat([pesquisa, new_pesquisa], keys = ['Enunciado', 'Contexto'])\n",
    "ambiente_extended = pd.concat([ambiente, new_ambiente], keys = ['Enunciado', 'Contexto'])\n",
    "saude_extended = pd.concat([saude, new_saude], keys = ['Enunciado', 'Contexto'])\n",
    "consumo_extended = pd.concat([consumo, new_consumo], keys = ['Enunciado', 'Contexto'])\n",
    "geografia_extended = pd.concat([geografia, new_geografia], keys = ['Enunciado', 'Contexto'])\n",
    "producao_extended = pd.concat([producao, new_producao], keys = ['Enunciado', 'Contexto'])\n",
    "computacional_extended = pd.concat([computacional, new_computacional], keys = ['Enunciado', 'Contexto'])\n",
    "imposto_extended = pd.concat([imposto, new_imposto], keys = ['Enunciado', 'Contexto'])\n",
    "\n",
    "df = pd.concat([mat, jogos_extended,comercial_extended,escolar_extended,outros_extended,\n",
    "           transito_extended,esporte_extended,fisica_extended,bancario_extended,\n",
    "           RH_extended,f_s_extended,populacao_extended,quimica_extended,\n",
    "           pessoa_extended,d_h_extended,seguranca_extended,pesquisa_extended,\n",
    "           ambiente_extended,saude_extended,consumo_extended,geografia_extended,\n",
    "           producao_extended,computacional_extended,imposto_extended])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matemático         261\n",
       "Comercial          240\n",
       "Jogos              192\n",
       "Escolar            158\n",
       "Outros             118\n",
       "Trânsito            86\n",
       "Esporte             84\n",
       "Física              72\n",
       "RH                  70\n",
       "Bancário            70\n",
       "Filmes e séries     60\n",
       "População           50\n",
       "Química             46\n",
       "Pessoa              44\n",
       "Data e hora         42\n",
       "Segurança           40\n",
       "Pesquisa            36\n",
       "Meio ambiente       36\n",
       "Saúde               34\n",
       "Consumo             32\n",
       "Geografia           22\n",
       "Produção            14\n",
       "Computacional       12\n",
       "Imposto             10\n",
       "Name: Contexto, dtype: int64"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Contexto.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=1100, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_df=0.5,min_df=5,stop_words=nlp.Defaults.stop_words)\n",
    "dtm=cv.fit_transform(df['Enunciado'])\n",
    "LDA=LatentDirichletAllocation(n_components=1100,random_state=42)\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste=[]\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    teste+=[' '.join([cv.get_feature_names()[index] for index in topic.argsort()[-25:]])]\n",
    "predictions=text_clf_lsvc2.predict(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Comercial', 'Comercial', 'Comercial', ..., 'Comercial',\n",
       "       'Comercial', 'Comercial'], dtype=object)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results=LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for elemento in topic_results.argmax(axis=1):\n",
    "    y_pred+=[predictions[elemento]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LDA']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Comercial          334\n",
       "Matemático         310\n",
       "Jogos              189\n",
       "Escolar            134\n",
       "Esporte             97\n",
       "Outros              94\n",
       "Trânsito            75\n",
       "Física              65\n",
       "RH                  63\n",
       "População           56\n",
       "Bancário            56\n",
       "Filmes e séries     55\n",
       "Segurança           42\n",
       "Data e hora         39\n",
       "Pessoa              36\n",
       "Química             36\n",
       "Pesquisa            35\n",
       "Meio ambiente       34\n",
       "Consumo             28\n",
       "Saúde               19\n",
       "Geografia           13\n",
       "Imposto              8\n",
       "Produção             7\n",
       "Computacional        4\n",
       "Name: LDA, dtype: int64"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LDA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matemático         261\n",
       "Comercial          240\n",
       "Jogos              192\n",
       "Escolar            158\n",
       "Outros             118\n",
       "Trânsito            86\n",
       "Esporte             84\n",
       "Física              72\n",
       "RH                  70\n",
       "Bancário            70\n",
       "Filmes e séries     60\n",
       "População           50\n",
       "Química             46\n",
       "Pessoa              44\n",
       "Data e hora         42\n",
       "Segurança           40\n",
       "Pesquisa            36\n",
       "Meio ambiente       36\n",
       "Saúde               34\n",
       "Consumo             32\n",
       "Geografia           22\n",
       "Produção            14\n",
       "Computacional       12\n",
       "Imposto             10\n",
       "Name: Contexto, dtype: int64"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Contexto.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Contexto</th>\n",
       "      <th>Enunciado</th>\n",
       "      <th>Id</th>\n",
       "      <th>Tópico</th>\n",
       "      <th>LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Matemático</td>\n",
       "      <td>Operadores aritméticos\\nQual o valor de X para...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matemático</td>\n",
       "      <td>Operadores aritméticos \\nQual o valor de Y par...</td>\n",
       "      <td>578.0</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Comercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Matemático</td>\n",
       "      <td>Arredondamento\\nEscreva um programa que aprese...</td>\n",
       "      <td>797.0</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Matemático</td>\n",
       "      <td>Ordem crescente\\nEscreva um programa que leia ...</td>\n",
       "      <td>1015.0</td>\n",
       "      <td>Estrutura condicional composta</td>\n",
       "      <td>Matemático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Matemático</td>\n",
       "      <td>Área do Círculo e Volume da Esfera\\nEscreva um...</td>\n",
       "      <td>825.0</td>\n",
       "      <td>Variáveis e Estrutura Sequencial</td>\n",
       "      <td>Trânsito</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Contexto, 0)</th>\n",
       "      <td>Imposto</td>\n",
       "      <td>Impostos Astrobaldo pormenorizadas comprada ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nada</td>\n",
       "      <td>Imposto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Contexto, 1)</th>\n",
       "      <td>Imposto</td>\n",
       "      <td>Impostos Astrobaldo pormenorizadas comprada ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nada</td>\n",
       "      <td>Imposto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Contexto, 2)</th>\n",
       "      <td>Imposto</td>\n",
       "      <td>Impostos Fredegunda pormenorizadas comprada ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nada</td>\n",
       "      <td>Imposto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Contexto, 3)</th>\n",
       "      <td>Imposto</td>\n",
       "      <td>Impostos Fredegunda pormenorizadas comprada ba...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nada</td>\n",
       "      <td>Imposto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Contexto, 4)</th>\n",
       "      <td>Imposto</td>\n",
       "      <td>Total acerca Compra acompanhar Imposto Para es...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nada</td>\n",
       "      <td>Jogos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1829 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Contexto                                          Enunciado  \\\n",
       "3              Matemático  Operadores aritméticos\\nQual o valor de X para...   \n",
       "4              Matemático  Operadores aritméticos \\nQual o valor de Y par...   \n",
       "6              Matemático  Arredondamento\\nEscreva um programa que aprese...   \n",
       "12             Matemático  Ordem crescente\\nEscreva um programa que leia ...   \n",
       "13             Matemático  Área do Círculo e Volume da Esfera\\nEscreva um...   \n",
       "...                   ...                                                ...   \n",
       "(Contexto, 0)     Imposto  Impostos Astrobaldo pormenorizadas comprada ba...   \n",
       "(Contexto, 1)     Imposto  Impostos Astrobaldo pormenorizadas comprada ba...   \n",
       "(Contexto, 2)     Imposto  Impostos Fredegunda pormenorizadas comprada ba...   \n",
       "(Contexto, 3)     Imposto  Impostos Fredegunda pormenorizadas comprada ba...   \n",
       "(Contexto, 4)     Imposto  Total acerca Compra acompanhar Imposto Para es...   \n",
       "\n",
       "                   Id                            Tópico         LDA  \n",
       "3              1000.0                       Ambientação      Outros  \n",
       "4               578.0                       Ambientação   Comercial  \n",
       "6               797.0                       Ambientação  Matemático  \n",
       "12             1015.0    Estrutura condicional composta  Matemático  \n",
       "13              825.0  Variáveis e Estrutura Sequencial    Trânsito  \n",
       "...               ...                               ...         ...  \n",
       "(Contexto, 0)     NaN                              Nada     Imposto  \n",
       "(Contexto, 1)     NaN                              Nada     Imposto  \n",
       "(Contexto, 2)     NaN                              Nada     Imposto  \n",
       "(Contexto, 3)     NaN                              Nada     Imposto  \n",
       "(Contexto, 4)     NaN                              Nada       Jogos  \n",
       "\n",
       "[1829 rows x 5 columns]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "contexto=[]\n",
    "for elemento in df['Contexto']:\n",
    "    contexto+=[elemento]\n",
    "lda=[]\n",
    "for elemento in df['LDA']:\n",
    "    lda+=[elemento]\n",
    "topico=[]\n",
    "for elemento in df['Tópico']:\n",
    "    topico+=[elemento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador=0\n",
    "y_test=[]\n",
    "y_pred=[]\n",
    "while(contador<len(contexto)):\n",
    "    if(topico[contador]!='Nada'):\n",
    "        y_test+=[contexto[contador]]\n",
    "        y_pred+=[lda[contador]]\n",
    "    contador+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 31   2   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1\n",
      "    0   0   0   0   0   0]\n",
      " [  2 108   0   1   0   0   2   1   0   0   0   1   4   0   0   0   0   0\n",
      "    1   0   0   0   0   0]\n",
      " [  0   2   4   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0  21   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  73   1   0   0   0   0   1   2   0   2   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  38   0   0   0   0   0   0   0   3   1   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  29   0   0   0   0   0   0   1   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0  32   0   0   3   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   6   0   0   0   0   3   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   4   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  1   3   0   0   0   0   0   0   0   0   0  90   0   0   0   1   0   1\n",
      "    0   0   0   0   0   0]\n",
      " [  1   9   0   0   1   0   0   1   0   0   0   3 237   0   6   0   0   1\n",
      "    0   0   0   0   1   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   4   0   0   1   1   0   0   0   0   0   1   5   0  46   0   1   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0  21   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0  23\n",
      "    0   0   0   0   0   0]\n",
      " [  0   3   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    4   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0  22   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  33   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  15   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  20   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0  41]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Bancário       0.89      0.89      0.89        35\n",
      "      Comercial       0.79      0.90      0.84       120\n",
      "  Computacional       1.00      0.67      0.80         6\n",
      "        Consumo       0.94      1.00      0.97        16\n",
      "    Data e hora       0.84      1.00      0.91        21\n",
      "        Escolar       0.96      0.92      0.94        79\n",
      "        Esporte       0.93      0.90      0.92        42\n",
      "Filmes e séries       0.91      0.97      0.94        30\n",
      "         Física       1.00      0.89      0.94        36\n",
      "      Geografia       1.00      0.55      0.71        11\n",
      "        Imposto       1.00      0.80      0.89         5\n",
      "          Jogos       0.89      0.94      0.91        96\n",
      "     Matemático       0.95      0.91      0.93       261\n",
      "  Meio ambiente       1.00      1.00      1.00        18\n",
      "         Outros       0.74      0.78      0.76        59\n",
      "       Pesquisa       0.90      1.00      0.95        18\n",
      "         Pessoa       0.95      0.95      0.95        22\n",
      "      População       0.88      0.92      0.90        25\n",
      "       Produção       0.80      0.57      0.67         7\n",
      "        Química       1.00      0.96      0.98        23\n",
      "             RH       1.00      0.94      0.97        35\n",
      "          Saúde       1.00      0.88      0.94        17\n",
      "      Segurança       0.95      1.00      0.98        20\n",
      "       Trânsito       0.98      0.95      0.96        43\n",
      "\n",
      "       accuracy                           0.91      1045\n",
      "      macro avg       0.93      0.89      0.90      1045\n",
      "   weighted avg       0.91      0.91      0.91      1045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
