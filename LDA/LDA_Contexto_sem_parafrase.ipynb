{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Enunciado</th>\n",
       "      <th>Tópico</th>\n",
       "      <th>Contexto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>Meu primeiro programa\\nEscreva um programa que...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>996</td>\n",
       "      <td>Impressão de caracteres na tela\\nEscreva um pr...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>Impressão de caracteres na tela (Bart Simpson)...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>Operadores aritméticos\\nQual o valor de X para...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>578</td>\n",
       "      <td>Operadores aritméticos \\nQual o valor de Y par...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                          Enunciado       Tópico  \\\n",
       "0   994  Meu primeiro programa\\nEscreva um programa que...  Ambientação   \n",
       "1   996  Impressão de caracteres na tela\\nEscreva um pr...  Ambientação   \n",
       "2   999  Impressão de caracteres na tela (Bart Simpson)...  Ambientação   \n",
       "3  1000  Operadores aritméticos\\nQual o valor de X para...  Ambientação   \n",
       "4   578  Operadores aritméticos \\nQual o valor de Y par...  Ambientação   \n",
       "\n",
       "     Contexto  \n",
       "0      Outros  \n",
       "1      Outros  \n",
       "2      Outros  \n",
       "3  Matemático  \n",
       "4  Matemático  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "df = pd.read_csv('../dados_categorizados_completo_novo.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matemático         261\n",
       "Comercial          120\n",
       "Jogos               96\n",
       "Escolar             79\n",
       "Outros              59\n",
       "Trânsito            43\n",
       "Esporte             42\n",
       "Física              36\n",
       "Bancário            35\n",
       "RH                  35\n",
       "Filmes e séries     30\n",
       "População           25\n",
       "Química             23\n",
       "Pessoa              22\n",
       "Data e hora         21\n",
       "Segurança           20\n",
       "Pesquisa            18\n",
       "Meio ambiente       18\n",
       "Saúde               17\n",
       "Consumo             16\n",
       "Geografia           11\n",
       "Produção             7\n",
       "Computacional        6\n",
       "Imposto              5\n",
       "Name: Contexto, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Contexto.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "X = df['Enunciado']\n",
    "y = df['Contexto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __call__(self, text):\n",
    "        doc=nlp(text)\n",
    "        tokens=[]\n",
    "        for token in doc:\n",
    "            if(token.text.isalpha() and len(token.text)>=2):\n",
    "                tokens+=[token]\n",
    "        return [t.lemma_ for t in tokens if t not in nlp.Defaults.stop_words]\n",
    "pipeline= LinearSVC(\n",
    "    penalty='l2',\n",
    "    loss='squared_hinge',\n",
    "    dual=True,\n",
    "    tol=0.001,\n",
    "    C=10.0,\n",
    "    multi_class='ovr',\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=10,\n",
    "    class_weight=None,\n",
    "    verbose=0,\n",
    "    random_state=None,\n",
    "    max_iter=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# vetor_X_train=[]\n",
    "# vetor_y_train=[]\n",
    "# vetor_X_test=[]\n",
    "# vetor_y_test=[]\n",
    "# split = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "# for train_index, val_index in split.split(X, y):\n",
    "#     vetor_X_train+=[X.iloc[train_index]]\n",
    "#     vetor_X_test+=[X.iloc[val_index]]\n",
    "#     vetor_y_train+=[y[train_index]]\n",
    "#     vetor_y_test+=[y[val_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contador=0\n",
    "# while(contador<len(vetor_X_train)):\n",
    "#     X_train=vetor_X_train[contador]\n",
    "#     y_train=vetor_y_train[contador]\n",
    "#     X_test=vetor_X_test[contador]\n",
    "    \n",
    "#     text_clf_lsvc2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=nlp.Defaults.stop_words,\n",
    "#                             tokenizer=LemmaTokenizer(),sublinear_tf=True)),\n",
    "#                             ('svd', TruncatedSVD(algorithm='randomized', n_components=300)),\n",
    "#                             ('clf',pipeline),\n",
    "#     ])\n",
    "#     text_clf_lsvc2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#     contador+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['acercar', 'algum', 'antar', 'apoiar', 'baixar', 'caminhar', 'ceder', 'cincar', 'comer', 'conhecer', 'custar', 'dever', 'devir', 'direito', 'entrar', 'estevar', 'estivar', 'falto', 'formar', 'grupar', 'irar', 'ligar', 'mear', 'nado', 'nenhum', 'nó', 'o', 'obrigar', 'oitavar', 'orar', 'outro', 'parecer', 'parir', 'pelar', 'pontar', 'pôr', 'quantum', 'quartar', 'querer', 'quietar', 'quintar', 'segundar', 'seriar', 'sobrar', 'suar', 'tardar', 'terceirar', 'umar', 'vezar', 'vir', 'vário'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words={'acerca', 'ademais', 'adeus',\n",
       "                                             'agora', 'ainda', 'algo',\n",
       "                                             'alguma...\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f92d1c4d150>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('svd',\n",
       "                 TruncatedSVD(algorithm='randomized', n_components=300,\n",
       "                              n_iter=5, random_state=None, tol=0.0)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=10.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=10,\n",
       "                           loss='squared_hinge', max_iter=10000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_lsvc2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=nlp.Defaults.stop_words,\n",
    "                            tokenizer=LemmaTokenizer(),sublinear_tf=True)),\n",
    "                            ('svd', TruncatedSVD(algorithm='randomized', n_components=300)),\n",
    "                            ('clf',pipeline),\n",
    "    ])\n",
    "text_clf_lsvc2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "                          evaluate_every=-1, learning_decay=0.7,\n",
       "                          learning_method='batch', learning_offset=10.0,\n",
       "                          max_doc_update_iter=100, max_iter=10,\n",
       "                          mean_change_tol=0.001, n_components=1100, n_jobs=None,\n",
       "                          perp_tol=0.1, random_state=42, topic_word_prior=None,\n",
       "                          total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv=CountVectorizer(max_df=0.5,min_df=5,stop_words=nlp.Defaults.stop_words)\n",
    "dtm=cv.fit_transform(df['Enunciado'])\n",
    "LDA=LatentDirichletAllocation(n_components=1100,random_state=42)\n",
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste=[]\n",
    "for i,topic in enumerate(LDA.components_):\n",
    "    teste+=[' '.join([cv.get_feature_names()[index] for index in topic.argsort()[-25:]])]\n",
    "predictions=text_clf_lsvc2.predict(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Comercial', 'Comercial', 'Matemático', ..., 'Comercial', 'Outros',\n",
       "       'Comercial'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_results=LDA.transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for elemento in topic_results.argmax(axis=1):\n",
    "    y_pred+=[predictions[elemento]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LDA']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matemático         272\n",
       "Comercial          123\n",
       "Jogos               95\n",
       "Escolar             71\n",
       "Outros              46\n",
       "Esporte             44\n",
       "Trânsito            38\n",
       "Filmes e séries     37\n",
       "Física              35\n",
       "Bancário            34\n",
       "RH                  34\n",
       "População           25\n",
       "Pessoa              24\n",
       "Química             22\n",
       "Segurança           21\n",
       "Meio ambiente       20\n",
       "Data e hora         20\n",
       "Consumo             18\n",
       "Saúde               18\n",
       "Pesquisa            16\n",
       "Produção            15\n",
       "Geografia            7\n",
       "Imposto              6\n",
       "Computacional        4\n",
       "Name: LDA, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.LDA.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matemático         261\n",
       "Comercial          120\n",
       "Jogos               96\n",
       "Escolar             79\n",
       "Outros              59\n",
       "Trânsito            43\n",
       "Esporte             42\n",
       "Física              36\n",
       "Bancário            35\n",
       "RH                  35\n",
       "Filmes e séries     30\n",
       "População           25\n",
       "Química             23\n",
       "Pessoa              22\n",
       "Data e hora         21\n",
       "Segurança           20\n",
       "Pesquisa            18\n",
       "Meio ambiente       18\n",
       "Saúde               17\n",
       "Consumo             16\n",
       "Geografia           11\n",
       "Produção             7\n",
       "Computacional        6\n",
       "Imposto              5\n",
       "Name: Contexto, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Contexto.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=df['Contexto']\n",
    "y_pred=df['LDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 31   3   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  1  98   0   2   0   0   2   0   0   0   1   1   6   0   0   0   1   0\n",
      "    6   0   1   1   0   0]\n",
      " [  0   0   4   0   0   0   0   0   2   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0  19   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    1   0   0   0   0   0]\n",
      " [  0   4   0   0   0  68   2   2   0   0   0   0   3   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  40   2   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  28   0   0   0   0   0   2   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30   0   0   1   4   0   0   0   0   0\n",
      "    0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   3   0   7   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  2   4   0   0   0   0   0   0   0   0   0  88   1   0   0   0   0   1\n",
      "    0   0   0   0   0   0]\n",
      " [  0   4   0   0   0   0   0   1   0   0   0   4 246   0   3   0   0   0\n",
      "    1   0   0   0   1   1]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   6   0   0   0   3   0   1   0   0   0   0   6   0  41   0   2   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0  16   1   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   2   0   0   0  20   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0  24\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    6   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0\n",
      "    0  22   0   0   0   0]\n",
      " [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  33   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  17   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  20   0]\n",
      " [  0   1   0   0   0   0   0   0   3   0   0   0   2   0   0   0   0   0\n",
      "    1   0   0   0   0  36]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Bancário       0.91      0.89      0.90        35\n",
      "      Comercial       0.80      0.82      0.81       120\n",
      "  Computacional       1.00      0.67      0.80         6\n",
      "        Consumo       0.89      1.00      0.94        16\n",
      "    Data e hora       0.95      0.90      0.93        21\n",
      "        Escolar       0.96      0.86      0.91        79\n",
      "        Esporte       0.91      0.95      0.93        42\n",
      "Filmes e séries       0.76      0.93      0.84        30\n",
      "         Física       0.86      0.83      0.85        36\n",
      "      Geografia       1.00      0.64      0.78        11\n",
      "        Imposto       0.83      1.00      0.91         5\n",
      "          Jogos       0.93      0.92      0.92        96\n",
      "     Matemático       0.90      0.94      0.92       261\n",
      "  Meio ambiente       0.90      1.00      0.95        18\n",
      "         Outros       0.89      0.69      0.78        59\n",
      "       Pesquisa       1.00      0.89      0.94        18\n",
      "         Pessoa       0.83      0.91      0.87        22\n",
      "      População       0.96      0.96      0.96        25\n",
      "       Produção       0.40      0.86      0.55         7\n",
      "        Química       1.00      0.96      0.98        23\n",
      "             RH       0.97      0.94      0.96        35\n",
      "          Saúde       0.94      1.00      0.97        17\n",
      "      Segurança       0.95      1.00      0.98        20\n",
      "       Trânsito       0.95      0.84      0.89        43\n",
      "\n",
      "       accuracy                           0.89      1045\n",
      "      macro avg       0.90      0.89      0.88      1045\n",
      "   weighted avg       0.90      0.89      0.89      1045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8928229665071771\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
