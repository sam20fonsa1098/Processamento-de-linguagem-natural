{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Enunciado</th>\n",
       "      <th>Tópico</th>\n",
       "      <th>Contexto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>Meu primeiro programa\\nEscreva um programa que...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>996</td>\n",
       "      <td>Impressão de caracteres na tela\\nEscreva um pr...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1326</td>\n",
       "      <td>Adição\\nSosígenes e Jocasta foram a um restaur...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Comercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1327</td>\n",
       "      <td>Subtração\\nHeráclito e Fredegunda foram a um r...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Comercial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1328</td>\n",
       "      <td>Multiplicação\\nVinte amigos foram a um rodízio...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Comercial</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                          Enunciado       Tópico  \\\n",
       "0   994  Meu primeiro programa\\nEscreva um programa que...  Ambientação   \n",
       "1   996  Impressão de caracteres na tela\\nEscreva um pr...  Ambientação   \n",
       "2  1326  Adição\\nSosígenes e Jocasta foram a um restaur...  Ambientação   \n",
       "3  1327  Subtração\\nHeráclito e Fredegunda foram a um r...  Ambientação   \n",
       "4  1328  Multiplicação\\nVinte amigos foram a um rodízio...  Ambientação   \n",
       "\n",
       "    Contexto  \n",
       "0     Outros  \n",
       "1     Outros  \n",
       "2  Comercial  \n",
       "3  Comercial  \n",
       "4  Comercial  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "\n",
    "df = pd.read_csv('enunciados_novos.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estrutura condicional encadeada        55\n",
       "Estrutura de repetição por contagem    52\n",
       "Estrutura condicional composta         44\n",
       "Estrutura de repetição por condição    43\n",
       "Vetor                                  41\n",
       "Matrizes                               36\n",
       "Operadores aritmétricos                29\n",
       "Strings                                20\n",
       "Ambientação                            16\n",
       "Estrutura sequencial                   12\n",
       "Name: Tópico, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Tópico'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Matemático         94\n",
       "Jogos              40\n",
       "Comercial          40\n",
       "Escolar            30\n",
       "Outros             23\n",
       "Física             14\n",
       "Esporte            13\n",
       "Pessoa             11\n",
       "Bancário           10\n",
       "Data e hora        10\n",
       "Trânsito            9\n",
       "RH                  8\n",
       "Português           7\n",
       "Filmes e séries     7\n",
       "Geografia           6\n",
       "População           6\n",
       "Consumo             5\n",
       "Saúde               4\n",
       "Computacional       3\n",
       "Segurança           3\n",
       "Pesquisa            2\n",
       "Imposto             2\n",
       "Loteria             1\n",
       "Name: Contexto, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Contexto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df['Enunciado']\n",
    "y = df['Contexto']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['acercar', 'algum', 'antar', 'apoiar', 'baixar', 'caminhar', 'ceder', 'cincar', 'comer', 'conhecer', 'custar', 'dever', 'devir', 'direito', 'entrar', 'estevar', 'estivar', 'falto', 'formar', 'grupar', 'irar', 'ligar', 'mear', 'nado', 'nenhum', 'nó', 'o', 'obrigar', 'oitavar', 'orar', 'outro', 'parecer', 'parir', 'pelar', 'pontar', 'pôr', 'quantum', 'quartar', 'querer', 'quietar', 'quintar', 'segundar', 'seriar', 'sobrar', 'suar', 'tardar', 'terceirar', 'umar', 'vezar', 'vir', 'vário'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words={'acerca', 'ademais', 'adeus',\n",
       "                                             'agora', 'ainda', 'algo',\n",
       "                                             'alguma...\n",
       "                                 strip_accents=None, sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f501c108cc0>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=10.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=10,\n",
       "                           loss='squared_hinge', max_iter=10000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LemmaTokenizer(object):\n",
    "    def __call__(self, text):\n",
    "        doc=nlp(text)\n",
    "        tokens=[]\n",
    "        for token in doc:\n",
    "            if(token.text.isalpha() and len(token.text)>=2):\n",
    "                tokens+=[token]\n",
    "        return [t.lemma_ for t in tokens if t not in nlp.Defaults.stop_words]\n",
    "pipeline= LinearSVC(\n",
    "    penalty='l2',\n",
    "    loss='squared_hinge',\n",
    "    dual=True,\n",
    "    tol=0.001,\n",
    "    C=10.0,\n",
    "    multi_class='ovr',\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=10,\n",
    "    class_weight=None,\n",
    "    verbose=0,\n",
    "    random_state=None,\n",
    "    max_iter=10000,\n",
    ")\n",
    "# RUN THIS CELL TO ADD STOPWORDS TO THE LINEAR SVC PIPELINE:\n",
    "text_clf_lsvc2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=nlp.Defaults.stop_words,\n",
    "                            tokenizer=LemmaTokenizer())),\n",
    "                     ('clf',pipeline),\n",
    "])\n",
    "text_clf_lsvc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 14  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  3  0  0  0  0  0  0  1  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 11  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 30  1  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  5  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "predictions = text_clf_lsvc2.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     Bancário       1.00      1.00      1.00         3\n",
      "    Comercial       1.00      0.88      0.93        16\n",
      "Computacional       0.00      0.00      0.00         0\n",
      "  Data e hora       1.00      0.60      0.75         5\n",
      "      Escolar       1.00      1.00      1.00         7\n",
      "      Esporte       1.00      1.00      1.00         6\n",
      "       Física       1.00      1.00      1.00         5\n",
      "    Geografia       1.00      1.00      1.00         1\n",
      "        Jogos       0.85      0.92      0.88        12\n",
      "   Matemático       0.88      0.97      0.92        31\n",
      "       Outros       0.71      0.83      0.77         6\n",
      "       Pessoa       1.00      0.50      0.67         2\n",
      "    População       0.00      0.00      0.00         1\n",
      "    Português       1.00      1.00      1.00         3\n",
      "           RH       0.67      1.00      0.80         2\n",
      "        Saúde       1.00      1.00      1.00         1\n",
      "    Segurança       1.00      1.00      1.00         1\n",
      "     Trânsito       1.00      0.67      0.80         3\n",
      "\n",
      "     accuracy                           0.90       105\n",
      "    macro avg       0.84      0.80      0.81       105\n",
      " weighted avg       0.92      0.90      0.90       105\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['acercar', 'algum', 'antar', 'apoiar', 'baixar', 'caminhar', 'ceder', 'cincar', 'comer', 'conhecer', 'custar', 'dever', 'devir', 'direito', 'entrar', 'estevar', 'estivar', 'falto', 'formar', 'grupar', 'irar', 'ligar', 'mear', 'nado', 'nenhum', 'nó', 'o', 'obrigar', 'oitavar', 'orar', 'outro', 'parecer', 'parir', 'pelar', 'pontar', 'pôr', 'quantum', 'quartar', 'querer', 'quietar', 'quintar', 'segundar', 'seriar', 'sobrar', 'suar', 'tardar', 'terceirar', 'umar', 'vezar', 'vir', 'vário'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X1 = df['Enunciado']\n",
    "y = df['Contexto']\n",
    "vect= TfidfVectorizer(stop_words=nlp.Defaults.stop_words,tokenizer=LemmaTokenizer())\n",
    "X=vect.fit_transform(X1)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_score = cross_val_score(pipeline, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc.: 0.86 [+/-0.07]\n"
     ]
    }
   ],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 36  0  1  0  0  0  0  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  1  0  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0  0  0  0  1  0  0  1  0  0  0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0 28  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 13  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 13  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0 38  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0 90  2  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  1  0  0  0  0  0  0  0  9 12  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  1  0  0  0  0  0  0  0  3  0  0  7  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  3  0  0  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  5  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0  0  1  0  0  0  0  0  5  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  1  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  0  0  1  0  0  0  0  0  0  0  0  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred=cross_val_predict(pipeline,X,y,cv=10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Bancário       1.00      0.90      0.95        10\n",
      "      Comercial       0.92      0.90      0.91        40\n",
      "  Computacional       0.67      0.67      0.67         3\n",
      "        Consumo       0.80      0.80      0.80         5\n",
      "    Data e hora       0.64      0.70      0.67        10\n",
      "        Escolar       0.90      0.93      0.92        30\n",
      "        Esporte       1.00      1.00      1.00        13\n",
      "Filmes e séries       1.00      0.86      0.92         7\n",
      "         Física       0.87      0.93      0.90        14\n",
      "      Geografia       1.00      1.00      1.00         6\n",
      "        Imposto       1.00      1.00      1.00         2\n",
      "          Jogos       0.86      0.95      0.90        40\n",
      "        Loteria       0.00      0.00      0.00         1\n",
      "     Matemático       0.80      0.96      0.87        94\n",
      "         Outros       0.71      0.52      0.60        23\n",
      "       Pesquisa       0.00      0.00      0.00         2\n",
      "         Pessoa       0.88      0.64      0.74        11\n",
      "      População       1.00      0.50      0.67         6\n",
      "      Português       1.00      0.71      0.83         7\n",
      "             RH       0.83      0.62      0.71         8\n",
      "          Saúde       0.50      0.25      0.33         4\n",
      "      Segurança       0.67      0.67      0.67         3\n",
      "       Trânsito       1.00      0.78      0.88         9\n",
      "\n",
      "       accuracy                           0.85       348\n",
      "      macro avg       0.78      0.71      0.74       348\n",
      "   weighted avg       0.85      0.85      0.84       348\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Enunciado']\n",
    "y = df['Tópico']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['acercar', 'algum', 'antar', 'apoiar', 'baixar', 'caminhar', 'ceder', 'cincar', 'comer', 'conhecer', 'custar', 'dever', 'devir', 'direito', 'entrar', 'estevar', 'estivar', 'falto', 'formar', 'grupar', 'irar', 'ligar', 'mear', 'nado', 'nenhum', 'nó', 'o', 'obrigar', 'oitavar', 'orar', 'outro', 'parecer', 'parir', 'pelar', 'pontar', 'pôr', 'quantum', 'quartar', 'querer', 'quietar', 'quintar', 'segundar', 'seriar', 'sobrar', 'suar', 'tardar', 'terceirar', 'umar', 'vezar', 'vir', 'vário'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words={'acerca', 'ademais', 'adeus',\n",
       "                                             'agora', 'ainda', 'algo',\n",
       "                                             'alguma...\n",
       "                                 strip_accents=None, sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<__main__.LemmaTokenizer object at 0x7f501a66d9b0>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=10.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=10,\n",
       "                           loss='squared_hinge', max_iter=10000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_lsvc2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=nlp.Defaults.stop_words,\n",
    "                            tokenizer=LemmaTokenizer())),\n",
    "                     ('clf',pipeline),\n",
    "])\n",
    "text_clf_lsvc2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  9  1  0  1  1  0  2  0  1]\n",
      " [ 0  2 13  0  1  0  1  1  0  0]\n",
      " [ 0  1  0 15  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  7  0  0  0  2  2]\n",
      " [ 0  3  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 11  1  0  0]\n",
      " [ 0  3  1  3  0  0  0  3  0  0]\n",
      " [ 0  1  0  0  3  0  1  0  3  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  5]]\n"
     ]
    }
   ],
   "source": [
    "predictions = text_clf_lsvc2.predict(X_test)\n",
    "print(metrics.confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['acercar', 'algum', 'antar', 'apoiar', 'baixar', 'caminhar', 'ceder', 'cincar', 'comer', 'conhecer', 'custar', 'dever', 'devir', 'direito', 'entrar', 'estevar', 'estivar', 'falto', 'formar', 'grupar', 'irar', 'ligar', 'mear', 'nado', 'nenhum', 'nó', 'o', 'obrigar', 'oitavar', 'orar', 'outro', 'parecer', 'parir', 'pelar', 'pontar', 'pôr', 'quantum', 'quartar', 'querer', 'quietar', 'quintar', 'segundar', 'seriar', 'sobrar', 'suar', 'tardar', 'terceirar', 'umar', 'vezar', 'vir', 'vário'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X1 = df['Enunciado']\n",
    "y = df['Tópico']\n",
    "vect= TfidfVectorizer(stop_words=nlp.Defaults.stop_words,tokenizer=LemmaTokenizer())\n",
    "X=vect.fit_transform(X1)\n",
    "cv_score = cross_val_score(pipeline, X, y, scoring='accuracy', cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc.: 0.65 [+/-0.13]\n"
     ]
    }
   ],
   "source": [
    "print('Acc.: %.2f [+/-%.2f]' % (cv_score.mean(), cv_score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8  2  1  1  1  0  0  2  1  0]\n",
      " [ 0 22  6  1  1  4  2  7  1  0]\n",
      " [ 0  6 46  0  1  0  1  1  0  0]\n",
      " [ 0  1  1 33  0  0  1  7  0  0]\n",
      " [ 0  2  3  1 33  0  3  0  3  7]\n",
      " [ 0  8  0  1  0  2  0  1  0  0]\n",
      " [ 0  1  2  1  0  1 30  0  1  0]\n",
      " [ 0  6  2  2  1  2  0 14  0  2]\n",
      " [ 2  1  1  2  4  0  2  0  5  3]\n",
      " [ 1  1  1  0  6  0  0  0  2 30]]\n"
     ]
    }
   ],
   "source": [
    "y_pred=cross_val_predict(pipeline,X,y,cv=10)\n",
    "print(confusion_matrix(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     precision    recall  f1-score   support\n",
      "\n",
      "                        Ambientação       0.73      0.50      0.59        16\n",
      "     Estrutura condicional composta       0.44      0.50      0.47        44\n",
      "    Estrutura condicional encadeada       0.73      0.84      0.78        55\n",
      "Estrutura de repetição por condição       0.79      0.77      0.78        43\n",
      "Estrutura de repetição por contagem       0.70      0.63      0.67        52\n",
      "               Estrutura sequencial       0.22      0.17      0.19        12\n",
      "                           Matrizes       0.77      0.83      0.80        36\n",
      "            Operadores aritmétricos       0.44      0.48      0.46        29\n",
      "                            Strings       0.38      0.25      0.30        20\n",
      "                              Vetor       0.71      0.73      0.72        41\n",
      "\n",
      "                           accuracy                           0.64       348\n",
      "                          macro avg       0.59      0.57      0.58       348\n",
      "                       weighted avg       0.64      0.64      0.64       348\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
