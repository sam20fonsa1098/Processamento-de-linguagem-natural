{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Enunciado</th>\n",
       "      <th>Tópico</th>\n",
       "      <th>Contexto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>994</td>\n",
       "      <td>Meu primeiro programa\\nEscreva um programa que...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>996</td>\n",
       "      <td>Impressão de caracteres na tela\\nEscreva um pr...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999</td>\n",
       "      <td>Impressão de caracteres na tela (Bart Simpson)...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Outros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>Operadores aritméticos\\nQual o valor de X para...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>578</td>\n",
       "      <td>Operadores aritméticos \\nQual o valor de Y par...</td>\n",
       "      <td>Ambientação</td>\n",
       "      <td>Matemático</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id                                          Enunciado       Tópico  \\\n",
       "0   994  Meu primeiro programa\\nEscreva um programa que...  Ambientação   \n",
       "1   996  Impressão de caracteres na tela\\nEscreva um pr...  Ambientação   \n",
       "2   999  Impressão de caracteres na tela (Bart Simpson)...  Ambientação   \n",
       "3  1000  Operadores aritméticos\\nQual o valor de X para...  Ambientação   \n",
       "4   578  Operadores aritméticos \\nQual o valor de Y par...  Ambientação   \n",
       "\n",
       "     Contexto  \n",
       "0      Outros  \n",
       "1      Outros  \n",
       "2      Outros  \n",
       "3  Matemático  \n",
       "4  Matemático  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('pt')\n",
    "\n",
    "\n",
    "df = pd.read_csv('../dados_categorizados_completo_novo.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1045, 4)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Enunciado']\n",
    "y = df['Contexto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 5 members, which is less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "vetor_X_train=[]\n",
    "vetor_y_train=[]\n",
    "vetor_X_test=[]\n",
    "vetor_y_test=[]\n",
    "split = StratifiedKFold(n_splits=10, random_state=None, shuffle=False)\n",
    "for train_index, val_index in split.split(X, y):\n",
    "    vetor_X_train+=[X.iloc[train_index]]\n",
    "    vetor_X_test+=[X.iloc[val_index]]\n",
    "    vetor_y_train+=[y[train_index]]\n",
    "    vetor_y_test+=[y[val_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_sentences(da):\n",
    "    strings=[]\n",
    "    for elemento in da['Enunciado']:\n",
    "        if(len(da)+len(strings)<maximum):\n",
    "            contador=0\n",
    "            lista=elemento.split()\n",
    "            while(contador<len(lista)):\n",
    "                if(lista[contador] in synonyms_lexicon):\n",
    "                    lista[contador]=synonyms_lexicon[lista[contador]][0]\n",
    "                contador+=1\n",
    "            strings+=[' '.join(lista)]\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    new_sentences = pd.Series(strings)\n",
    "    return new_sentences\n",
    "\n",
    "def get_synonyms_lexicon(path):\n",
    "    synonyms_lexicon = {}\n",
    "    text_entries = [l.strip() for l in open(path).readlines()]\n",
    "    for e in text_entries:\n",
    "        e = e.split(' ')\n",
    "        k = e[0]\n",
    "        v = e[1:len(e)]\n",
    "        synonyms_lexicon[k] = v\n",
    "    return synonyms_lexicon\n",
    "\n",
    "synonyms_lexicon = get_synonyms_lexicon('./arq3.txt')\n",
    "\n",
    "class LemmaTokenizer(object):\n",
    "    def __call__(self, text):\n",
    "        doc=nlp(text)\n",
    "        tokens=[]\n",
    "        for token in doc:\n",
    "            if(token.text.isalpha() and len(token.text)>=2):\n",
    "                tokens+=[token]\n",
    "        return [t.lemma_ for t in tokens if t not in nlp.Defaults.stop_words]\n",
    "pipeline= LinearSVC(\n",
    "    penalty='l2',\n",
    "    loss='squared_hinge',\n",
    "    dual=True,\n",
    "    tol=0.001,\n",
    "    C=10.0,\n",
    "    multi_class='ovr',\n",
    "    fit_intercept=True,\n",
    "    intercept_scaling=10,\n",
    "    class_weight=None,\n",
    "    verbose=0,\n",
    "    random_state=None,\n",
    "    max_iter=10000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['acercar', 'algum', 'antar', 'apoiar', 'baixar', 'caminhar', 'ceder', 'cincar', 'comer', 'conhecer', 'custar', 'dever', 'devir', 'direito', 'entrar', 'estevar', 'estivar', 'falto', 'formar', 'grupar', 'irar', 'ligar', 'mear', 'nado', 'nenhum', 'nó', 'o', 'obrigar', 'oitavar', 'orar', 'outro', 'parecer', 'parir', 'pelar', 'pontar', 'pôr', 'quantum', 'quartar', 'querer', 'quietar', 'quintar', 'segundar', 'seriar', 'sobrar', 'suar', 'tardar', 'terceirar', 'umar', 'vezar', 'vir', 'vário'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "/home/samuel/anaconda3/lib/python3.7/site-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "contador=0\n",
    "predictions=[]\n",
    "while(contador<len(vetor_X_train)):\n",
    "    X_train=vetor_X_train[contador]\n",
    "    y_train=vetor_y_train[contador]\n",
    "    X_test=vetor_X_test[contador]\n",
    "    y_test=vetor_y_test[contador]\n",
    "    test = np.c_[X_train[:np.newaxis], y_train[:np.newaxis]]\n",
    "    df = pd.DataFrame(test, columns=['Enunciado', 'Contexto'])\n",
    "    \n",
    "    maximum = df.Contexto.value_counts().max()\n",
    "    g = df.groupby('Contexto')\n",
    "\n",
    "\n",
    "    mat = g.get_group('Matemático')\n",
    "    comercial = g.get_group('Comercial')\n",
    "    jogos = g.get_group('Jogos')\n",
    "    escolar = g.get_group('Escolar')\n",
    "    outros = g.get_group('Outros')\n",
    "    transito = g.get_group('Trânsito')\n",
    "    esporte = g.get_group('Esporte')\n",
    "    fisica = g.get_group('Física')\n",
    "    bancario = g.get_group('Bancário')\n",
    "    RH = g.get_group('RH')\n",
    "    f_s = g.get_group('Filmes e séries')\n",
    "    populacao = g.get_group('População')\n",
    "    quimica = g.get_group('Química')\n",
    "    pessoa = g.get_group('Pessoa')\n",
    "    d_h = g.get_group('Data e hora')\n",
    "    seguranca = g.get_group('Segurança')\n",
    "    ambiente = g.get_group('Meio ambiente')\n",
    "    pesquisa = g.get_group('Pesquisa')\n",
    "    saude = g.get_group('Saúde')\n",
    "    consumo = g.get_group('Consumo')\n",
    "    geografia = g.get_group('Geografia')\n",
    "    producao = g.get_group('Produção')\n",
    "    imposto = g.get_group('Imposto')\n",
    "    computacional = g.get_group('Computacional')\n",
    "    \n",
    "    new_mat = get_new_sentences(mat)\n",
    "    new_jogos = get_new_sentences(jogos)\n",
    "    new_comercial = get_new_sentences(comercial)\n",
    "    new_escolar = get_new_sentences(escolar)\n",
    "    new_outros = get_new_sentences(outros)\n",
    "    new_transito = get_new_sentences(transito)\n",
    "    new_esporte = get_new_sentences(esporte)\n",
    "    new_fisica = get_new_sentences(fisica)\n",
    "    new_bancario = get_new_sentences(bancario)\n",
    "    new_RH = get_new_sentences(RH)\n",
    "    new_f_s = get_new_sentences(f_s)\n",
    "    new_populacao = get_new_sentences(populacao)\n",
    "    new_quimica = get_new_sentences(quimica)\n",
    "    new_pessoa = get_new_sentences(pessoa)\n",
    "    new_d_h = get_new_sentences(d_h)\n",
    "    new_seguranca = get_new_sentences(seguranca)\n",
    "    new_pesquisa = get_new_sentences(pesquisa)\n",
    "    new_ambiente = get_new_sentences(ambiente)\n",
    "    new_saude = get_new_sentences(saude)\n",
    "    new_consumo = get_new_sentences(consumo)\n",
    "    new_geografia = get_new_sentences(geografia)\n",
    "    new_producao = get_new_sentences(producao)\n",
    "    new_computacional = get_new_sentences(computacional)\n",
    "    new_imposto = get_new_sentences(imposto)\n",
    "\n",
    "    \n",
    "    new_jogos = pd.DataFrame(new_jogos,columns=['Enunciado'])\n",
    "    new_jogos['Contexto'] = 'Jogos'\n",
    "\n",
    "    new_comercial = pd.DataFrame(new_comercial,columns=['Enunciado'])\n",
    "    new_comercial['Contexto'] = 'Comercial'\n",
    "\n",
    "    new_escolar = pd.DataFrame(new_escolar,columns=['Enunciado'])\n",
    "    new_escolar['Contexto'] = 'Escolar'\n",
    "\n",
    "    new_outros = pd.DataFrame(new_outros,columns=['Enunciado'])\n",
    "    new_outros['Contexto'] = 'Outros'\n",
    "\n",
    "    new_transito = pd.DataFrame(new_transito,columns=['Enunciado'])\n",
    "    new_transito['Contexto'] = 'Trânsito'\n",
    "\n",
    "    new_esporte = pd.DataFrame(new_esporte,columns=['Enunciado'])\n",
    "    new_esporte['Contexto'] = 'Esporte'\n",
    "\n",
    "    new_fisica = pd.DataFrame(new_fisica,columns=['Enunciado'])\n",
    "    new_fisica['Contexto'] = 'Física'\n",
    "\n",
    "    new_bancario = pd.DataFrame(new_bancario,columns=['Enunciado'])\n",
    "    new_bancario['Contexto'] = 'Bancário'\n",
    "\n",
    "    new_RH = pd.DataFrame(new_RH,columns=['Enunciado'])\n",
    "    new_RH['Contexto'] = 'RH'\n",
    "\n",
    "    new_f_s = pd.DataFrame(new_f_s,columns=['Enunciado'])\n",
    "    new_f_s['Contexto'] = 'Filmes e séries'\n",
    "\n",
    "    new_populacao = pd.DataFrame(new_populacao,columns=['Enunciado'])\n",
    "    new_populacao['Contexto'] = 'População'\n",
    "\n",
    "    new_quimica = pd.DataFrame(new_quimica,columns=['Enunciado'])\n",
    "    new_quimica['Contexto'] = 'Química'\n",
    "\n",
    "    new_pessoa = pd.DataFrame(new_pessoa,columns=['Enunciado'])\n",
    "    new_pessoa['Contexto'] = 'Pessoa'\n",
    "\n",
    "    new_d_h = pd.DataFrame(new_d_h,columns=['Enunciado'])\n",
    "    new_d_h['Contexto'] = 'Data e hora'\n",
    "\n",
    "    new_seguranca = pd.DataFrame(new_seguranca,columns=['Enunciado'])\n",
    "    new_seguranca['Contexto'] = 'Segurança'\n",
    "\n",
    "    new_pesquisa = pd.DataFrame(new_pesquisa,columns=['Enunciado'])\n",
    "    new_pesquisa['Contexto'] = 'Pesquisa'\n",
    "\n",
    "    new_ambiente = pd.DataFrame(new_ambiente,columns=['Enunciado'])\n",
    "    new_ambiente['Contexto'] = 'Meio ambiente'\n",
    "\n",
    "    new_saude = pd.DataFrame(new_saude,columns=['Enunciado'])\n",
    "    new_saude['Contexto'] = 'Saúde'\n",
    "\n",
    "    new_consumo = pd.DataFrame(new_consumo,columns=['Enunciado'])\n",
    "    new_consumo['Contexto'] = 'Consumo'\n",
    "\n",
    "    new_geografia = pd.DataFrame(new_geografia,columns=['Enunciado'])\n",
    "    new_geografia['Contexto'] = 'Geografia'\n",
    "\n",
    "    new_producao = pd.DataFrame(new_producao,columns=['Enunciado'])\n",
    "    new_producao['Contexto'] = 'Produção'\n",
    "\n",
    "    new_computacional= pd.DataFrame(new_computacional,columns=['Enunciado'])\n",
    "    new_computacional['Contexto'] = 'Computacional'\n",
    "\n",
    "    new_imposto= pd.DataFrame(new_imposto,columns=['Enunciado'])\n",
    "    new_imposto['Contexto'] = 'Imposto'\n",
    "    \n",
    "    df = pd.concat([mat, jogos_extended,comercial_extended,escolar_extended,outros_extended,\n",
    "               transito_extended,esporte_extended,fisica_extended,bancario_extended,\n",
    "               RH_extended,f_s_extended,populacao_extended,quimica_extended,\n",
    "               pessoa_extended,d_h_extended,seguranca_extended,pesquisa_extended,\n",
    "               ambiente_extended,saude_extended,consumo_extended,geografia_extended,\n",
    "               producao_extended,computacional_extended,imposto_extended])\n",
    "    \n",
    "    X_train = df['Enunciado']\n",
    "    y_train = df['Contexto']\n",
    "    \n",
    "    text_clf_lsvc2 = Pipeline([('tfidf', TfidfVectorizer(stop_words=nlp.Defaults.stop_words,\n",
    "                            tokenizer=LemmaTokenizer())),\n",
    "                     ('clf',pipeline),\n",
    "    ])\n",
    "    text_clf_lsvc2.fit(X_train, y_train)\n",
    "\n",
    "    predictions+=[text_clf_lsvc2.predict(X_test)]\n",
    "\n",
    "    contador+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for lista in predictions:\n",
    "    for elemento in lista:\n",
    "        y_pred+=[elemento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_sla=[]\n",
    "for lista in vetor_y_test:\n",
    "    for elemento in lista:\n",
    "        y_test_sla+=[elemento]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 34   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0 119   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   1   0   0   0]\n",
      " [  0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0  16   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0  20   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   1]\n",
      " [  0   0   0   0   0  79   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  42   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  30   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0  34   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0   0   0   0  10   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0   0   0   0   0  95   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   4   0   0   0   1   0   0   0   0   0   0 240   0  16   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0   0   0   0   0   4   0  54   0   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  18   0   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  22   0\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  25\n",
      "    0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    7   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0  23   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0  35   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0  16   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0  20   0]\n",
      " [  0   1   0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0   0   0   0  40]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "       Bancário       0.97      0.97      0.97        35\n",
      "      Comercial       0.96      0.99      0.98       120\n",
      "  Computacional       1.00      1.00      1.00         6\n",
      "        Consumo       0.94      1.00      0.97        16\n",
      "    Data e hora       1.00      0.95      0.98        21\n",
      "        Escolar       0.96      1.00      0.98        79\n",
      "        Esporte       1.00      1.00      1.00        42\n",
      "Filmes e séries       1.00      1.00      1.00        30\n",
      "         Física       1.00      0.94      0.97        36\n",
      "      Geografia       1.00      0.91      0.95        11\n",
      "        Imposto       1.00      1.00      1.00         5\n",
      "          Jogos       0.99      0.99      0.99        96\n",
      "     Matemático       0.97      0.92      0.94       261\n",
      "  Meio ambiente       1.00      1.00      1.00        18\n",
      "         Outros       0.77      0.92      0.84        59\n",
      "       Pesquisa       1.00      1.00      1.00        18\n",
      "         Pessoa       1.00      1.00      1.00        22\n",
      "      População       1.00      1.00      1.00        25\n",
      "       Produção       1.00      1.00      1.00         7\n",
      "        Química       1.00      1.00      1.00        23\n",
      "             RH       0.97      1.00      0.99        35\n",
      "          Saúde       1.00      0.94      0.97        17\n",
      "      Segurança       1.00      1.00      1.00        20\n",
      "       Trânsito       0.95      0.93      0.94        43\n",
      "\n",
      "       accuracy                           0.96      1045\n",
      "      macro avg       0.98      0.98      0.98      1045\n",
      "   weighted avg       0.97      0.96      0.97      1045\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9645933014354067\n"
     ]
    }
   ],
   "source": [
    "print(metrics.accuracy_score(y_test_sla,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_etc = confusion_matrix(y_test_sla, y_pred)\n",
    "row_sums = mat_etc.sum(axis=1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_conf_mx = mat_etc / row_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Bancário','Comercial','Computacional','Consumo','Data e hora','Escolar','Esportes',\n",
    "         'Filmes e séries','Física','Geogragia','Imposto','Jogos','Matemático',\n",
    "          'Meio ambiente','Outros','Pesquisa','Pessoa','População','Produção',\n",
    "         'Química','RH','Saúde','Segurança','Trânsito']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
